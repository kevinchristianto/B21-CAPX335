{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dataset Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ycz0MWq9UaR8"
      },
      "source": [
        "# Dataset Preprocessing\n",
        "\n",
        "This notebook is used to preprocess the dataset that we use from Kaggle by **Tedi Setiady** (https://www.kaggle.com/tedisetiady/leaf-rice-disease-indonesia).\n",
        "\n",
        "The process of this notebook is described as follows:\n",
        "\n",
        "1.   Download the corresponding dataset from Kaggle using Kaggle CLI\n",
        "2.   Extract the downloaded dataset\n",
        "3.   Resize the extracted dataset to match the size of **MobileNetV2** input shape\n",
        "4.   Split up the resized dataset into three subset (**training**, **validation**, and **testing**)\n",
        "5.   Compress those dataset into one single zip archive for the convenience of storing\n",
        "6.   Copy zipped dataset into Google Drive\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAlrmXYEWNcb"
      },
      "source": [
        "> **First step first, upload kaggle.json to this colab local runtime before executing below cell**\n",
        ">\n",
        "> **If kaggle.json already uploaded, then run below cell to install and import required libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtGBXK4CsRLZ"
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!pip install -q split-folders\n",
        "\n",
        "import splitfolders as sf\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "from google.colab import drive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owhZ0HqXW6xZ"
      },
      "source": [
        "> **Mount Google Drive into `/drive`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF_tRW15z38u"
      },
      "source": [
        "drive.mount('/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slkVDKtxW74p"
      },
      "source": [
        "> **Download the dataset from Kaggle using Kaggle CLI, then extract the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1hribcDTrf3"
      },
      "source": [
        "!kaggle datasets download -d tedisetiady/leaf-rice-disease-indonesia\n",
        "zip_loc = 'leaf-rice-disease-indonesia.zip'\n",
        "zip_ref = zipfile.ZipFile(zip_loc, 'r')\n",
        "zip_ref.extractall('/content/tedi')     # leaf-rice-disease-indonesia.zip\n",
        "zip_ref.close()\n",
        "\n",
        "!rm leaf-rice-disease-indonesia.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_I0T1JFXGj3"
      },
      "source": [
        "> **Prepare some folder for resizing the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOklmACPT_NC"
      },
      "source": [
        "!mkdir -p 'Resized/Blast'\n",
        "!mkdir -p 'Resized/Blight'\n",
        "!mkdir -p 'Resized/Tungro'\n",
        "!mv /content/tedi/blast '/content/tedi/Blast'\n",
        "!mv /content/tedi/blight '/content/tedi/Blight'\n",
        "!mv /content/tedi/tungro '/content/tedi/Tungro'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSViqwccXN8O"
      },
      "source": [
        "> **Resize the dataset into 224 by 224 (if the image is 1:1) or 224 by 400 (if the image is not 1:1, but 400 is just the max height so the resized width will always be 224) to match the MobileNetV2 input shape**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZplSK_qoUBbM"
      },
      "source": [
        "IMAGE_DIR = '/content/tedi/'\n",
        "RESIZED_DIR = '/content/Resized/'\n",
        "for root, dirs, files in os.walk(IMAGE_DIR):\n",
        "    for f in files:\n",
        "        resized_filename = os.path.join(RESIZED_DIR, os.path.split(root)[-1], f)\n",
        "        try:\n",
        "            im = Image.open(os.path.join(root, f))\n",
        "            im.convert('RGB')\n",
        "            width, height = im.size\n",
        "            if width == height:\n",
        "                im = im.resize((224, 224), Image.LANCZOS)\n",
        "            else:\n",
        "                im.thumbnail((224, 400), Image.LANCZOS)\n",
        "            im.save(resized_filename)\n",
        "        except:\n",
        "            print(\"Error creating thumbnail for {}\".format(os.path.join(root, f)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkwNK_xLYf6y"
      },
      "source": [
        "> **Split the resized dataset into three subset (training, validation, and test).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RIjybF2UBS7"
      },
      "source": [
        "DATASET_DIR = '/content/Resized'\n",
        "sf.fixed(DATASET_DIR, output='/content/Splitted/', seed=22, fixed=(15, 10), oversample=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGlDi60bYlZz"
      },
      "source": [
        "> **Compress the resized dataset into one single archive, then copy to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daElxcdvUBJM"
      },
      "source": [
        "path = '/content/Splitted/'\n",
        "with zipfile.ZipFile('dataset.zip', 'w', zipfile.ZIP_DEFLATED) as zipObj:\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for f in files:\n",
        "            zipObj.write(os.path.join(root, f), os.path.relpath(os.path.join(root, f), os.path.join(path, '..')))\n",
        "\n",
        "!cp dataset.zip '/drive/My Drive/Datasets/dataset-tedi.zip'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}